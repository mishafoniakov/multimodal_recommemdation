{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Representation text dataset and building BERT-vectors\n",
    "Here we work with text dataset and create BERT vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ft5KEGvwkDT5"
   },
   "outputs": [],
   "source": [
    "# function for file opening from folder\n",
    "path = '/Users/mishafoniakov/Documents/Thesis'\n",
    "def file(folder, file):\n",
    "    return os.path.join(path, folder, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Representation of classes and functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Dataset class: it is responsible for all operations with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tdYaXdoulB-T"
   },
   "outputs": [],
   "source": [
    "class TextDataset:\n",
    "    def __init__(self, text_dir_path):\n",
    "        self.text_dir_path = text_dir_path\n",
    "    \n",
    "    def json_file_opening(self, json_file, attr_1, attr_2, dictionary=False, reshaping=False, tensor=False):\n",
    "        with open(json_file, 'r') as file:\n",
    "            img_features = [(json.loads(line)[attr_1],\n",
    "                 json.loads(line)[attr_2])\n",
    "                  for line in file]\n",
    "        img_list = [feature[0] for feature in img_features]\n",
    "        feature_list = [feature[1] for feature in img_features]\n",
    "        if dictionary == False:\n",
    "            return img_list, feature_list\n",
    "        else:\n",
    "            dict_list = {}\n",
    "            assert len(img_list) == len(feature_list)\n",
    "            for i in range(len(img_list)):\n",
    "                if reshaping == True:\n",
    "                    dict_list[img_list[i]] = np.array(feature_list[i]).reshape(1, -1)\n",
    "                elif tensor == True:\n",
    "                    dict_list[img_list[i]] = torch.FloatTensor(feature_list[i]).unsqueeze(dim=0)\n",
    "                else:\n",
    "                    dict_list[img_list[i]] = feature_list[i]\n",
    "            return dict_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. BERT class: it is responsible for building BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#BERT model representation\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased', output_hidden_states=True)\n",
    "bert_model = bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT:\n",
    "    def __init__(self, model, img_list, text_data):\n",
    "        self.model = model\n",
    "        self.img_list = img_list\n",
    "        self.text_data = text_data\n",
    "\n",
    "    def bert_embeddings_list(self):\n",
    "        with open(file('Dataset_preparation', 'bert.json'), 'w') as bert:\n",
    "            pass\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(device)\n",
    "        n = len(self.text_data)\n",
    "        for i in range(n):\n",
    "            encodings = tokenizer(self.text_data[i], padding=True, return_tensors='pt', max_length=50, add_special_tokens = True)\n",
    "            encodings = encodings.to(device)\n",
    "            with torch.no_grad():\n",
    "                embeds = self.model(**encodings)\n",
    "            sentence_embedding = embeds[0][0, 0, :].cpu().tolist()\n",
    "            img_bert = {'img': self.img_list[i], 'bert': sentence_embedding}\n",
    "            with open(file('Dataset_preparation', 'bert.json'), 'a') as bert:\n",
    "                json.dump(img_bert, bert)\n",
    "                bert.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building BERT-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We form text array with all text files\n",
    "text = TextDataset(file('Dataset_representation/Dataset_texts', 'image_big_text_dataset.json'))\n",
    "text_description = text.json_file_opening(file('Dataset_representation/Dataset_texts', \n",
    "                                               'image_big_text_dataset.json'), 'img', 'txt', dictionary=True, reshaping=False, tensor=False)\n",
    "#We form image array with all image files\n",
    "img_list = list(text_description.keys())\n",
    "img_number = len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We build BERT-vectors using obtained image and text array\n",
    "bert = BERT(bert_model, img_list, text_data)\n",
    "bert_embeddings = bert.bert_embeddings_list()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
